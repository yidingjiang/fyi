<!DOCTYPE HTML>
<html lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yiding Jiang</title>

  <meta name="author" content="Yiding Jiang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/icon.jpeg">
</head>

<body>
  <table
    style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr style="padding:0px">
                <td style="padding:2.5%;width:63%;vertical-align:middle">
                  <p style="text-align:center">
                    <name>Yiding Jiang</name>
                  </p>
                  <p style="text-align:center">
                    yd &lt;last name&gt; at cmu dot edu
                  </p>
                  <p>I am a PhD student at Machine Learning Department of Carnegie
                    Mellon University where I work with
                    Professor <a href="https://zicokolter.com/">Zico Kolter</a>. My research is supported by the Google
                    PhD Fellowship.</p>

                  <p>Previously, I was an AI Resident at Google Research.
                    I obtained my bachelor of science in Electrical
                    Engineering and Computer Science at UC Berkeley, where I worked on robotics and
                    generative models advised by Professor <a
                      href="https://web.archive.org/web/20180924140954/http://goldberg.berkeley.edu/">Ken Goldberg</a>.
                    I have also spent time as a research intern at Meta AI
                    Research and Cerebras Systems.
                  </p>
                  <p style="text-align:center">
                    <a href="https://scholar.google.com/citations?user=x9qzWg8AAAAJ&hl=en">Google Scholar</a>
                    &nbsp/&nbsp
                    <a href="https://github.com/yidingjiang">GitHub</a> &nbsp/&nbsp
                    <a href="https://twitter.com/yidingjiang">Twitter</a> &nbsp/&nbsp
                    <a href="https://www.linkedin.com/in/yiding-jiang-600bb6116/"> LinkedIn </a>
                  </p>
                </td>
                <td style="padding:2.5%;width:40%;max-width:40%">
                  <a href="images/photo.jpeg"><img style="width:80%;max-width:80%" alt="profile photo"
                      src="images/photo.jpeg" class="hoverZoomLink"></a>
                </td>
              </tr>
            </tbody>
          </table>
          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <tr>
                <td style="padding:20px;width:100%;vertical-align:middle">
                  <heading>Research</heading>
                  <p>
                  <div onmouseover="document.getElementById('hidden_research').style.display = 'block';"
                    onmouseout="document.getElementById('hidden_research').style.display='none';">
                    I am interested in understanding how high-capacity machine learning systems built on deep neural
                    networks learn and generalize, and using the insights to improve them further. This entails research
                    on a spectrum of topics including representation learning, reinforcement learning, non-convex
                    optimization, and generalization
                    -- both concrete generalization bounds, and less well-understood empirical phenomena such as
                    out-of-distribution and zero-shot generalization.
                  </div>
                  </p>
                </td>
              </tr>
            </tbody>
          </table>

          <table
            style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
            <tbody>
              <p align="right"> * indicates equal contribution</p>
              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                  <table
                    style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>

                      <tr>
                        <td style="padding: 20px; width: 15%; vertical-align: top;">
                          <!-- <img src="images/boosting.png" alt="PontTuset" width="160" style="border-style: none;"> -->
                        </td>
                        <td width="100%" valign="middle" style="display: table; min-height: 120px; max-height: 150px;">
                          <div style="display: table-cell; vertical-align: middle;">
                            <!-- Adjust the min-height and max-height values as needed -->
                            <a href="https://arxiv.org/abs/2310.03957" id="MCG_journal">
                              <papertitle>Understanding prompt engineering may not require rethinking generalization
                              </papertitle>
                            </a>
                            <br>
                            <a href="https://home.victorakinwande.com/">Victor Akinwande</a>,
                            <strong>Yiding Jiang</strong>,
                            <a href="https://dsam99.github.io/">Dylan Sam</a>,
                            <a href="https://zicokolter.com/">J. Zico Kolter</a>
                            <br>
                            <em>Sampling and Optimization in Discrete Space workshop, ICML 2023</em>
                            <font color="red">
                              <strong> (Outstanding Paper) </strong>
                            </font>
                          </div>
                        </td>
                      </tr>


                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle;text-align:center;">
                          <img src="images/boosting.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td width="100%" valign="top" style="display: table; min-height: 150px; max-height: 150px;">
                          <div style="display: table-cell; vertical-align: middle;">
                            <!-- Adjust the min-height value as needed -->
                            <a href="https://arxiv.org/abs/2306.14101" id="MCG_journal">
                              <papertitle>Language models are weak learners
                              </papertitle>
                            </a>
                            <br>
                            <a href="https://www.linkedin.com/in/hmanikan/">Hariharan Manikandan</a>,
                            <strong>Yiding Jiang</strong>,
                            <a href="https://zicokolter.com/">J. Zico Kolter</a>
                            <br>
                            <em>NeurIPS</em>, 2023
                            <br>
                            <em>Efficient Systems for Foundation Models workshop, ICML 2023</em>
                          </div>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/nft.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td width="100%" valign="top" style="display: table; min-height: 150px; max-height: 150px;">
                          <div style="display: table-cell; vertical-align: middle;">
                            <a href="https://arxiv.org/abs/2305.13546" id="MCG_journal">
                              <papertitle>Neural Functional Transformers
                              </papertitle>
                            </a>
                            <br>
                            <a href="https://bland.website/">Allan Zhou</a>,
                            <a href="https://www.linkedin.com/in/kaienyang">Kaien Yang</a>,
                            <strong>Yiding Jiang</strong>,
                            <a href="https://kayburns.github.io/">Kaylee Burns</a>,
                            <a href="https://winniexu.ca/">Winnie Xu</a>,
                            <a href="https://ssokota.github.io/">Samuel Sokota</a>,
                            <a href="https://zicokolter.com/">J. Zico Kolter</a>,
                            <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
                            <br>
                            <em>NeurIPS</em>, 2023
                          </div>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/nfn.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td width="100%" valign="top" style="display: table; min-height: 150px; max-height: 150px;">
                          <div style="display: table-cell; vertical-align: middle;">
                            <a href="https://arxiv.org/abs/2302.14040" id="MCG_journal">
                              <papertitle>Permutation equivariant neural functionals
                              </papertitle>
                            </a>
                            <br>
                            <a href="https://bland.website/">Allan Zhou</a>,
                            <a href="https://www.linkedin.com/in/kaienyang">Kaien Yang</a>,
                            <a href="https://kayburns.github.io/">Kaylee Burns</a>,
                            <a href="https://www.unibo.it/sitoweb/adriano.cardace2/en">Adriano Cardace</a>,
                            <strong>Yiding Jiang</strong>,
                            <a href="https://ssokota.github.io/">Samuel Sokota</a>,
                            <a href="https://zicokolter.com/">J. Zico Kolter</a>,
                            <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
                            <br>
                            <em>NeurIPS</em>, 2023
                          </div>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/inter_tensor.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td width="100%" valign="top" style="display: table; min-height: 150px; max-height: 150px;">
                          <div style="display: table-cell; vertical-align: middle;">
                            <a href="https://arxiv.org/abs/2306.04793" id="MCG_journal">
                              <papertitle>On the Joint Interaction of Models, Data, and Features
                              </papertitle>
                            </a>
                            <br>
                            <strong>Yiding Jiang</strong>,
                            <a href="https://kebaek.github.io">Christina Baek</a>,
                            <a href="https://zicokolter.com/">J. Zico Kolter</a>
                            <br>
                            <em>High-dimensional Learning Dynamics workshop, ICML 2023</em>
                          </div>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/ede.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td width="100%" valign="top" style="display: table; min-height: 150px; max-height: 150px;">
                          <div style="display: table-cell; vertical-align: middle;">
                            <a href="https://arxiv.org/abs/2306.05483" id="MCG_journal">
                              <papertitle>On the Importance of Exploration for Generalization in Reinforcement Learning
                              </papertitle>
                            </a>
                            <br>
                            <strong>Yiding Jiang</strong>,
                            <a href="https://zicokolter.com/">J. Zico Kolter</a>,
                            <a href="https://rraileanu.github.io/">Roberta Raileanu</a>
                            <br>
                            <em>NeurIPS</em>, 2023
                            <br>
                            <a href="https://github.com/facebookresearch/ede">[code]</a>
                          </div>
                        </td>
                      </tr>

                      <tr style="display: table-row;">
                        <td style="padding:20px;width:15%;vertical-align:middle;">
                          <img src="images/love.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td style="vertical-align: middle; width: 100%; min-height: 120px; max-height: 150px;">
                          <a href="https://arxiv.org/abs/2212.04590" id="MCG_journal">
                            <papertitle>Learning Options via Compression</papertitle>
                          </a>
                          <br>
                          <strong>Yiding Jiang</strong>*,
                          <a href="https://cs.stanford.edu/people/evanliu/">Evan Z. Liu*</a>,
                          <a href="https://ben-eysenbach.github.io/">Benjamin Eysenbach</a>,
                          <a href="https://zicokolter.com/">J. Zico Kolter</a>,
                          <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
                          <br>
                          <em>NeurIPS</em>, 2022
                          <br>
                          <a href="https://github.com/yidingjiang/love">[code]</a>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/aline.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td style="vertical-align: middle; width: 100%; min-height: 120px; max-height: 150px;">
                          <a href="https://arxiv.org/abs/2206.13089" id="MCG_journal">
                            <papertitle>Agreement-on-the-line: Predicting the Performance of Neural Networks under
                              Distribution Shift</papertitle>
                          </a>
                          <br>
                          <a href="https://kebaek.github.io">Christina Baek</a>,
                          <strong>Yiding Jiang</strong>,
                          <a href="https://www.cs.cmu.edu/~aditirag/">Aditi Raghunathan</a>,
                          <a href="https://zicokolter.com/">J. Zico Kolter</a>
                          <br>
                          <em>NeurIPS</em>, 2022 <font color="red"><strong> (oral) </strong></font>
                          <br>
                          <em>Principles of Distribution Shift Workshop, ICML 22</em>
                          <br>
                          <p></p>
                        </td>
                      </tr>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/gde.jpeg" alt="PontTuset" class="paper-image" />
                        </td>
                        <td style="vertical-align: middle; width: 100%; min-height: 120px; max-height: 150px;">
                          <a href="https://arxiv.org/abs/2106.13799" id="MCG_journal">
                            <papertitle>Assessing Generalization of SGD via Disagreement</papertitle>
                          </a>
                          <br>
                          <strong>
                            Yiding Jiang*</strong>, <a href="http://www.cs.cmu.edu/~vaishnan/home/index.html">Vaishnavh
                            Nagarajan*</a>, <a href="https://kebaek.github.io">Christina Baek</a>, <a
                            href="https://zicokolter.com/">J. Zico Kolter</a>
                          <br>
                          <em>ICLR</em>, 2022 <font color="red"><strong> (spotlight) </strong></font>
                          <br>
                          <em>Workshop on Overparameterization: Pitfalls & Opportunities, ICML 2021</em>
                          <br>
                          <a
                            href="https://blog.ml.cmu.edu/2022/03/04/assessing-generalization-of-sgd-via-disagreement/">[blog
                            post]</a>
                          <p></p>
                          <!-- <p>We summarize the findings from the first competition on prediction generalization in deep
                            learning and present the solutions from top competitors.</p> -->
                        </td>
                      </tr>

                    <tbody>

                      <tr>
                        <td style="padding:20px;width:15%;vertical-align:middle">
                          <img src="images/ane.png" alt="PontTuset" class="paper-image" />
                        </td>
                        <td style="vertical-align: middle; width: 100%; min-height: 120px; max-height: 150px;">
                          <a href="https://arxiv.org/abs/2104.11902" id="MCG_journal">
                            <papertitle>Ask & Explore: Grounded Question Answering for Curiosity-Driven Exploration
                            </papertitle>
                          </a>
                          <br>
                          <a href="https://jivatneet.github.io/">Jivat Neet Kaur</a>, <strong>
                            Yiding Jiang</strong>, <a href="https://www.cs.cmu.edu/~pliang/">Paul Pu Liang</a>
                          <br>
                          <em>Arxiv</em>, 2021
                          <br>
                          <em>Workshop on Embodied Multimodal Learning, ICLR 2021</em>
                          <br>
                          <p></p>
                          <!-- <p>We summarize the findings from the first competition on prediction generalization in deep
                              learning and present the solutions from top competitors.</p> -->
                        </td>
                      </tr>

                    </tbody>

                    <tr>
                      <td style="padding:20px;width:15%;vertical-align:middle">
                        <img src="images/pgdl.jpeg" alt="PontTuset" class="paper-image" />
                      </td>
                      <td style="vertical-align: middle; width: 100%; min-height: 120px; max-height: 150px;">
                        <a href="http://proceedings.mlr.press/v133/jiang21a/jiang21a.pdf" id="MCG_journal">
                          <papertitle>Methods and Analysis of The First Competition in Predicting Generalization of
                            Deep Learning</papertitle>
                        </a>
                        <br>
                        <strong>
                          Yiding Jiang</strong>, <a href="https://parthnatekar.github.io/">Parth Natekar*</a>, Manik
                        Sharma*, Sumukh K Aithal*, Dhruva Kashyap*,
                        Natarajan
                        Subramanyam*,<a href="https://cadurosar.github.io/">Carlos Lassance*</a>, <a
                          href="http://danroy.org/">Daniel M. Roy</a>, <a href="https://gkdz.org/">Gintare Karolina
                          Dziugaite</a>, <a href="http://sgunasekar.github.io/">Suriya Gunasekar</a>,
                        <a href="https://guyon.chalearn.org/">Isabelle Guyon</a>, Pierre Foret, Scott Yak, <a
                          href="https://people.csail.mit.edu/hmobahi/">Hossein Mobahi</a>, <a
                          href="https://www.neyshabur.net/">Behnam Neyshabur*</a>, <a
                          href="https://bengio.abracadoudou.com/">Samy Bengio</a>

                        <br>
                        <em>PMLR: NeurIPS 2020 Competition and Demonstration Track</em>, 2020
                        <br>
                        <a href="https://sites.google.com/view/pgdl2020/">[competiton page]</a> &nbsp;
                        <a href="https://competitions.codalab.org/competitions/25301">[Codalab]</a> &nbsp;
                        <a href="https://github.com/google-research/google-research/tree/master/pgdl"> [competition
                          dataset]</a> &nbsp;
                        <a
                          href="https://competitions.codalab.org/competitions/25301#learn_the_details-get_starting_kit">
                          [competition code]</a>
                        <p></p>
                        <!-- <p>We summarize the findings from the first competition on prediction generalization in deep
                            learning and present the solutions from top competitors.</p> -->
                      </td>
                    </tr>

                    <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src="images/fantastic_beast.jpg" alt="PontTuset" class="paper-image" />
                      </td>
                      <td width="75%" valign="middle">
                        <a href="https://arxiv.org/abs/1912.02178" id="MCG_journal">
                          <papertitle>Fantastic Generalization Measures and Where to Find Them</papertitle>
                        </a>
                        <br>
                        <strong>Yiding Jiang*</strong>, <a href="https://www.neyshabur.net/">Behnam Neyshabur*</a>, <a
                          href="https://people.csail.mit.edu/hmobahi/">Hossein Mobahi</a>, <a
                          href="https://dilipkay.wordpress.com/">Dilip Krishnan</a>, <a
                          href="https://bengio.abracadoudou.com/">Samy Bengio</a>
                        <br>
                        <em>ICLR</em>, 2020
                        <br>
                        <em>"<a href="https://sites.google.com/view/sedl-neurips-2019/">Science meets the Engineering
                            of Deep Learning</a>" workshop, NeurIPS 2019</em>
                        <font color="red"><strong> (oral) </strong></font>
                        <br>
                        <p></p>
                        <!-- <p>We propose a procedure that captures the causal realtionship between complexity measures
                            and
                            the generalization gap of neural networks, and conduct a large scale study to showcase the
                            effectiveness of the procedure; we also observed that many popular complexity measures do
                            not
                            capture the desired property.</p> -->
                      </td>
                    </tr>

                    <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src="images/fg_sonic.png" alt="PontTuset" class="paper-image" />
                      </td>
                      <td width="75%" valign="middle">
                        <a href="https://arxiv.org/abs/1912.02975" id="MCG_journal">
                          <papertitle>Observational Overfitting in Reinforcement Learning</papertitle>
                        </a>
                        <br>
                        <a href="https://xingyousong.github.io/">Xingyou Song</a>, <strong>Yiding Jiang</strong>, <a
                          href="https://stephentu.github.io/">Stephen
                          Tu</a>, <a href="https://yilundu.github.io/">Yilun Du</a>, <a
                          href="https://www.neyshabur.net/">Behnam Neyshabur</a>
                        <br>
                        <em>ICLR</em>, 2020
                        <br>
                        <p></p>
                        <!-- <p>
                            We prove the existence of overfitting for reinforcement learning in high-dimensional state
                            space
                            and demonstrate the benefit of implicit regularization in this setting.
                          </p> -->
                      </td>
                    </tr>

                    <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src="images/hal.gif" alt="PontTuset" class="paper-image" />
                      </td>
                      <td width="75%" valign="middle">
                        <a href="https://arxiv.org/abs/1906.07343" id="MCG_journal">
                          <papertitle>Language as an Abstraction for Hierarchical Deep Reinforcement Learning
                          </papertitle>
                        </a>
                        <br>
                        <strong>Yiding Jiang</strong>, <a href="https://sites.google.com/view/gugurus">Shixiang
                          Gu</a>, <a href="https://www.cs.ubc.ca/~murphyk/">Kevin Murphy</a>, <a
                          href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
                        <br>
                        <em>NeurIPS</em>, 2019
                        <br>
                        <a href="https://sites.google.com/view/hal-demo">[project page]</a> &nbsp;
                        <a href="https://github.com/google-research/clevr_robot_env">[environment]</a>
                        <p></p>
                        <!-- <p>We use compositional language as the abstraction between high-level and low-level policies
                            to
                            solve complex and temporally extended tasks.</p> -->
                      </td>
                    </tr>

                    <tr>
                      <td style="padding:20px;width:25%;vertical-align:middle">
                        <img src="images/ago.gif" alt="PontTuset" class="paper-image" />
                      </td>
                      <td width="100%" valign="middle" style="display: table; min-height: 150px; max-height: 150px;">
                        <div style="display: table-cell; vertical-align: middle;">
                          <a href="https://goldberg.berkeley.edu/pubs/2019-CASE-adversarial-objects.pdf"
                            id="MCG_journal">
                            <papertitle>Adversarial Grasp Objects</papertitle>
                          </a>
                          <br>
                          <a href="https://www.linkedin.com/in/dwang14/">David Wang*</a>, <a
                            href="https://www.linkedin.com/in/tsengdavid/">David Tseng*</a>, <a
                            href="https://www.linkedin.com/in/pusong-li-99ab9658/">Pusong Li*</a>, <strong>Yiding
                            Jiang*</strong>, <a href="https://www.linkedin.com/in/menglong-guo-268aab175/">Menglong
                            Guo</a>,
                          <a href="https://mjd3.github.io/">Michael Danielczuk</a>, <a
                            href="https://www.jeff-mahler.com/">Jeffrey Mahler</a>, <a
                            href="https://www.cs.unc.edu/~jeffi/">Jeffrey Ichnowski</a>, <a
                            href="https://goldberg.berkeley.edu/">Ken Goldberg</a>
                          <br>
                          <em>CASE</em>, 2019
                          <br>
                          <a
                            href="https://spectrum.ieee.org/automaton/robotics/robotics-hardware/uc-berkeley-adversarial-objects-for-robots">IEEE
                            Spectrum article</a>
                          <p></p>
                          <!-- <p>
                            We explore methods of synthesizing 3D objects that are "adversarial" to grasp planners.
                          </p> -->
                        </div>
                      </td>
                    </tr>

                    <tr>
                      <td style="padding:10px;width:25%;vertical-align:middle">
                        <img src="images/margin_dist.png" alt="PontTuset" class="paper-image" />
                      </td>
                      <td width="75%" valign="middle">
                        <a href="https://arxiv.org/abs/1810.00113" id="MCG_journal">
                          <papertitle>Predicting the Generalization Gap in Deep Networks with Margin Distributions
                          </papertitle>
                        </a>
                        <br>
                        <strong>Yiding Jiang</strong>, <a href="https://dilipkay.wordpress.com/">Dilip Krishnan</a>,
                        <a href="https://people.csail.mit.edu/hmobahi/">Hossein Mobahi</a>, <a
                          href="https://bengio.abracadoudou.com/">Samy Bengio</a>
                        <br>
                        <em>ICLR</em>, 2019
                        <br>
                        <a href="https://ai.googleblog.com/2019/07/predicting-generalization-gap-in-deep.html">blog
                          post</a>
                        <p></p>
                        <!-- <p>
                            We introduce Generalization Gap Predictor (GGP) and propose a new GGP based on the hidden
                            activations of deep neural networks that outperforms existing predictors.
                          </p> -->
                      </td>
                    </tr>

                </tbody>
              </table>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <heading>Teaching</heading>
                    </td>
                  </tr>
                </tbody>
              </table>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <ul>
                    <li>Teaching Assistant, 10-708 Probablistic Graphical Models. Carnegie Mellon University. Fall 2022.
                    </li>
                    <li>Teaching Assistant, 10-725 Convex Optimization. Carnegie Mellon University. Fall 2021.</li>
                    <li>Reader, CS170 Efficient Algorithms and Intractable Problems. University of California, Berkeley.
                      Fall 2017.</li>
                  </ul>
                  <!-- <tr>
                    <td width="75%" valign="middle">
                      <p>Teaching Assistant, 10-725 Convex Optimization, Carnegie Mellon Univeristy Fall 2021.</p>
                    </td>
                  </tr> -->

                </tbody>
              </table>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:20px;width:100%;vertical-align:middle">
                      <heading>Project</heading>
                    </td>
                  </tr>
                </tbody>
              </table>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>

                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/hal.gif" alt="PontTuset" class="paper-image" />
                    </td>
                    <td width="75%" valign="middle">
                      <papertitle>CLEVR-Robot Environment</papertitle>
                      <br>
                      <a href="https://github.com/google-research/clevr_robot_env">GitHub repository</a>
                      <p></p>
                      <p>The CLEVR-Robot environment is a reinforcement learning environment that aims to provide a
                        research platform for developing RL agents at the intersection of <strong>vision,
                          language</strong>, and <strong>continuous/discrete control</strong>.</p>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:10px;width:25%;vertical-align:middle">
                      <img src="images/margin_dist.png" alt="PontTuset" class="paper-image" />
                    </td>
                    <td width="75%" valign="middle">
                      <papertitle>Deep Model Generalization Dataset (<strong>DEMOGEN</strong>)</papertitle>
                      <br>
                      <a href="https://github.com/google-research/google-research/tree/master/demogen">GitHub
                        repository</a>
                      <p></p>
                      <p>The DEMOGEN dataset is a the collection of 756 trained neural network models and the code
                        to
                        use them. This is the same dataset used by our work "Predicting the Generalization Gap in
                        Deep
                        Networks with Margin Distributions", and is to our knoweledge the first dataset of
                        <strong>models</strong> for studying generalization.
                      </p>
                    </td>
                  </tr>

                  <tr>
                    <td style="padding:20px;width:25%;vertical-align:middle">
                      <img src="images/city2city.png" alt="PontTuset" class="paper-image" />
                    </td>
                    <td width="75%" valign="middle">
                      <papertitle>City2City</papertitle>
                      <br>
                      <a href="https://bland.website/city2city/">Project Page</a>
                      <p></p>
                      <p>City2City is a project that restyles Google streetview images of one city with another
                        city.
                      </p>
                    </td>
                  </tr>

                </tbody>
              </table>

              <table
                style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                <tbody>
                  <tr>
                    <td style="padding:0px">
                      <br>
                      <p style="text-align:right;font-size:small;">
                        Credits for <a href="https://github.com/jonbarron/jonbarron_website">Template</a> go to <a
                          href="https://jonbarron.info/">Jon Barron</a>.
                      </p>
                    </td>
                  </tr>
                </tbody>
              </table>
        </td>
      </tr>
  </table>
</body>

</html>